#!/usr/bin/env python3

import os
import subprocess
import json
import time
import base64
import requests
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from datetime import datetime
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
#import tempfile

def get_executable_path(executable_name):
    """指定された実行ファイルのパスを which コマンドで取得する"""
    try:
        result = subprocess.run(['which', executable_name], capture_output=True, text=True, check=True)
        path = result.stdout.strip()
        return path
    except subprocess.CalledProcessError:
        print(f"警告: {executable_name} が見つかりませんでした。")
        return None



# Chromium と ChromeDriver のパスを動的に取得
chromium_path = get_executable_path("chromium")
chromedriver_path = get_executable_path("chromedriver")

from bs4 import BeautifulSoup
import time

def download_images(url, download_folder="images"):
# WebDriverの初期化 (Chromeを使用)
    service = Service(chromedriver_path)
    options = webdriver.ChromeOptions()
    options.binary_location = chromium_path
    options.add_argument('--headless')
    options.add_argument('--disable-gpu')
    options.add_argument('--window-size=1920x1080')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument("--disable-application-cache")
    options.add_argument("--incognito")
    driver = webdriver.Chrome(service=service, options=options)

# Webページの読み込み
    driver.get(url)
    time.sleep(5)  # ページの読み込みを待機

# BeautifulSoupでページを解析
    soup = BeautifulSoup(driver.page_source, 'html.parser')
# 画像のURLを取得
    img_tags = soup.find_all('img')
    img_urls = [img['src'] for img in img_tags if img.get('src')]

# ダウンロードフォルダの作成
    if not os.path.exists(download_folder):
        os.makedirs(download_folder)

# 画像をダウンロード
    for i, img_url in enumerate(img_urls):
        try:
            # 相対URLを絶対URLに変換
            if not img_url.startswith('http'):
                img_url = url + img_url if url.endswith('/') else url + '/' + img_url
            img_data = requests.get(img_url).content
            file_name = os.path.join(download_folder, f"image_{i+1:03d}.jpg")
            with open(file_name, 'wb') as f:
                f.write(img_data)
            print(f"Downloaded: {file_name}")
        
        except Exception as e:
            print(f"Error downloading {img_url}: {e}")

    driver.quit()

# 例: Googleのロゴ画像をダウンロード
download_images("https://www.google.com/")
