#!/usr/bin/env python3

import os
import sys
import requests
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time

def download_images(url, download_folder=None):

    if download_folder is None:
        download_folder = "images"

    # WebDriverの初期化 (Chromeを使用)
    service = Service()
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')  # ヘッドレスモードで実行する場合
    driver = webdriver.Chrome(service=service, options=options)

    # Webページの読み込み
    driver.get(url)
    time.sleep(5)  # ページの読み込みを待機

    # BeautifulSoupでページを解析
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # 画像のURLを取得
    img_tags = soup.find_all('img')
    img_urls = [img['src'] for img in img_tags if img.get('src')]

    # ダウンロードフォルダの作成
    if not os.path.exists(download_folder):
        os.makedirs(download_folder)

    # 画像をダウンロード
    for i, img_url in enumerate(img_urls):
        try:
            # 相対URLを絶対URLに変換
            if not img_url.startswith('http'):
                img_url = url + img_url if url.endswith('/') else url + '/' + img_url

            img_data = requests.get(img_url).content
            file_name = os.path.join(download_folder, f"image_{i+1:03d}.jpg")

            with open(file_name, 'wb') as f:
                f.write(img_data)
            print(f"Downloaded: {file_name}")

        except Exception as e:
            print(f"Error downloading {img_url}: {e}")

    driver.quit()

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: webpicget <url> [download_folder]")
        sys.exit(1)

    url = sys.argv[1]
    download_folder = sys.argv[2] if len(sys.argv) > 2 else None

    download_images(url, download_folder)
