#!/usr/bin/env python3

import os
import sys
import subprocess
import requests
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import time
from urllib.parse import urlparse, urljoin
import mimetypes
import re
from tqdm import tqdm

def get_executable_path(executable_name):
    """指定された実行ファイルのパスを which コマンドで取得する"""
    try:
        sys.stdout.write("\033[2K\r")
        print(f"\rSearching for {executable_name}...", end="")
        result = subprocess.run(['which', executable_name], capture_output=True, text=True, check=True)
        path = result.stdout.strip()
        return path
    except subprocess.CalledProcessError:
        print(f"\r警告: {executable_name} が見つかりませんでした。")
        return None

def get_file_extension(url):
    """ URL から拡張子を取得する (なければ Content-Type をチェック) """
    parsed_url = urlparse(url)
    ext = os.path.splitext(parsed_url.path)[1]  # ".jpg" ".png" など

    if ext:  # 拡張子が取得できたらそれを使う
        return ext

    # 拡張子がない場合は Content-Type から推測
    try:
        response = requests.head(url, allow_redirects=True)
        content_type = response.headers.get("Content-Type", "")
        ext = mimetypes.guess_extension(content_type)
        return ext if ext else ".jpg"  # 不明なら jpg にする
    except:
        return ".jpg"

def sanitize_filename(filename):
    """ファイル名として安全な文字列に変換する"""
    return re.sub(r'[^\w\-_.]', '_', filename)

def download_images(url, download_folder=None):

    if download_folder is None:
        download_folder = "images"

    # Webページの読み込み
    sys.stdout.write("\033[2K\r")
    print(f"\rLoading page...", end="")
    driver.get(url)
    time.sleep(5)  # ページの読み込みを待機

    # BeautifulSoupでページを解析
    sys.stdout.write("\033[2K\r")
    print(f"\rAnalyzing page...", end="")
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # 画像のURLを取得
    sys.stdout.write("\033[2K\r")
    print(f"\rImage data is being acquired...", end="")
    img_tags = soup.find_all('img')
    img_urls = [(img.get('src'), img.get('alt')) for img in img_tags if img.get('src')]

    # 画像の合計数を表示
    total_images = len(img_urls)
    success = total_images

    # ダウンロードフォルダの作成
    os.makedirs(download_folder, exist_ok=True)

    # 画像をダウンロード
    for i, (img_src, alt_text) in tqdm(enumerate(img_urls), total=total_images, desc="Downloading", unit="images"):
        try:
            # 相対URLを絶対URLに変換
            img_url = urljoin(url, img_src)

            # 拡張子を取得
            ext = get_file_extension(img_url)

            # ファイル名を決定
            if alt_text:
                file_name = sanitize_filename(alt_text) + ext
            else:
                file_name = sanitize_filename(os.path.basename(urlparse(img_url).path)) + ext

            file_name = os.path.join(download_folder, file_name)

            # 画像をダウンロード
            img_data = requests.get(img_url).content
            with open(file_name, 'wb') as f:
                f.write(img_data)

        except Exception as e:
            print(f"\rError downloading {img_url}: {e}")
            success -= 1

    print(f"\rdownloaded {success} images.")

    #print()  # 改行

    driver.quit()

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: webpicget <url> [download_folder]")
        sys.exit(1)

    url = sys.argv[1]
    download_folder = sys.argv[2] if len(sys.argv) > 2 else None

    # Chromium と ChromeDriver のパスを動的に取得
    chromium_path = get_executable_path("chromium")
    chromedriver_path = get_executable_path("chromedriver")

    if chromium_path != None and chromedriver_path != None:
        # WebDriverの初期化 (Chromiumを使用)
        sys.stdout.write("\033[2K\r")
        print(f"\rChromium is starting...", end="") 
        service = Service(executable_path=chromedriver_path)
        options = Options()
        options.binary_location = chromium_path
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')

        driver = webdriver.Chrome(service=service, options=options)
        download_images(url, download_folder)
    else:
        sys.exit(1)
